%\VignetteEngine{knitr::knitr}

\documentclass[a4paper,9pt]{article}

<<style-knitr, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

%\VignetteIndexEntry{EvoTraceR}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{placeins}
\usepackage{url}
\usepackage{tcolorbox}
\usepackage{authblk}
\usepackage{underscore}

\begin{document}

\title{EvoTraceR: Analysis of Amplicon Sequence Variants after performing an experiment through the EVoBC kit}

\author[1]{Lucrezia Patruno}
\author[2]{Daniele Ramazzottii}
\author[3]{Dawid Nowak}

\affil[1]{Dept. of Informatics, Systems and Communication, Univ. of Milan-Bicocca, Milan, Italy.}
\affil[2]{Dept. of Medicine and Surgery, Univ. of Milan-Bicocca, Monza, Italy.}
\affil[3]{Sandra and Edward Meyer Cancer Center, Weill Cornell Medicine, New York, USA.}

\date{\today}
\maketitle

\begin{tcolorbox}{\bf Overview.} 
EvoTraceR is the computational tool inside the project EboBC. After performing EvoBC experiments in the lab, this tool can be exploited to perform the analysis of Amplicon Sequence Variants.
It preprocesses the input to identify all ASVs, then performs multi-sequence alignment to identify mutations and finally performs the phylogeny reconstruction.

\vspace{1.0cm}

{\em In this vignette, we present the usage of EvoTraceR.}

\vspace{1.0cm}

\renewcommand{\arraystretch}{1.5}

\end{tcolorbox}

<<include=FALSE>>=
library(knitr)
opts_chunk$set(
concordance = TRUE,
background = "#f3f3ff",
dev = "cairo_pdf"
)
@

\newpage

\tableofcontents

\section{Using the EvoTraceR R package}

In order to perform the analysis, there are multiple functions that perform the different steps of the analysis pipeline. 
The first step initializes the EvoTraceR object, which is a list that gets populated step-by-step with multiple fields containing the result of the analysis.

<<req>>=
library("EvoTraceR")
# Run in case reticulate was setup manually:
# library(reticulate)
# reticulate::use_condaenv('EvoTraceR_enviroment')
@


The initialization function computes the set of Amplicon Sequence Variants.
It calls trimmomatic and flash tools to perform adapters trimming, discard low quality bases and merge forward and reverse reads.
The main parameters for the initialization are the directory where the output will be stored and one of the following: 
input directory: in this case users have the fastq files and want to perform the whole analysis using EvoTraceR. In this case they need to provide the path to the folder containing the fastq (which may be compressed), and then they can provide any additional parameter for dada2 functions. 
trimmomatic_path: Local path to the executable of Trimmomatic. 
flash_path. Local path to the executable of \texttt{Flash}.
Important: each fastq file pair (forward and reverse) must be associated to the sample on which the experiment was performed. The sample can be either the organ of the moouse or the an ID for the timepoint in case longitudinal data is provided. 
In order for EvoTraceR to associate each fastq pair to its sample users have two options: 
one is to name the fastq following this pattern: FILEPREFIX_SAMPLE_FILESUFFIX_RX.fastq, where FILEPREFIX and FILESUFFIX can be any string (without the "_" character). In this case EvoTraceR will consider as sample ID the second field separated by the underscore. 
The second option is to provide a list that associates each filename (without the suffix _R1 and _R2) to the corresponding sample. For example, if we have forward and reverse files named file1_R1.fastq and file1_R2.fastq that correspond to organ PRL (code for Prostate Left), than the parameter should be set as: map_file_sample = c("file1" = "PRL")). 

Users can skip the initialization step and the subsequent one (function asv_analysis) for this vignette, as the output has been pre-computed and can be loaded by calling data(EvoTraceR_object). 
In this example we will work with fastq files named according to the pattern, providing their directory as input.

<<example_input_parameters, eval=FALSE>>=
input_dir = system.file("extdata", "input", package = "EvoTraceR")
output_dir = system.file("extdata", "output", package = "EvoTraceR")
@

We can now perform the initialization. 

<<example_initialization, eval=FALSE>>=
EvoTraceR_object = initialize_EvoTraceR(input_dir = input_dir, 
                                        output_dir = output_dir, 
                                        trimmomatic_path = '~/Trimmomatic 0.xx/trimmomatic-0.xx.jar',
                                        flash_path = '~/*/FLASH-x.x.x/flash')
@

During the above computation, Trimmomatic and Flash were run and all ASVs are detected. The result is an object of class EvoTraceR, which is populated by 5 fields: a dataframe
that tracks the number of sequences during all preliminary steps. map_file_sample is a dataframe with as many rows as the number of input datasets, and for each input stores the sample (e.g. organ or day for longitudinal data) to which it is associated.
asv_prefilter: dataframe that stores all sequences detected after running Trimmomatic and Flash.

Next, we need to run the following function to perform the analysis. This function performs the analysis on ASV sequences identified by the previous steps and aligns them to the reference sequence.
First, it pools together those sequences characterized by a Hamming distance equals or lower than 2. 
Then it performs pairwise alignment using Needleman-Wunsch global alignment algorithm implemented in function \texttt{pairwiseAlignment}
in package \texttt{pwalign}, aligning each sequence to the original barcode considered in the analysis 
(See the pwalign documentation \href{https://bioconductor.org/packages/release/bioc/html/pwalign.html}{here} for more details).
After identifying all indels (insertions are identified by their start position and number of nucleoides inserted, while deletions are identified by their start and end position),
it removes the ones that are too small and don't span any cut site: to perform this filter, it exapnds the start and end position by the number of bases specified in the parameter \texttt{cleaning_window},
it counts the number of cut sites spanned after the expantion and it removes those that span 0 sites.
Next, it pools together those sequences that differ by one another only by substitutions.
Then it computes the normalized counts of each ASV in each sample, dividing each count by the total number of sequences for each sample and multiplying by 1e6, yelding Counts Per Million (CPM).
After normalization, counts are summed in each ASV, and those sequences showing a frequency lower than the threshold specified in parameter \texttt{asv_count_cutoff} are removed.
Finally, it performs filtering of the sequences based on their flanking sequences.
Then, using the CPM it computes different statistics for the final ASVS, storing:
the relative frequency of all ASVs in each sample. 
the relative frequency of each ASV in the samples.
the counts for each ASV normalized to the counts of the sample with maximum frequency.
the frequency of the different ASVs in each sample.

Users can skip this step for this vignette, as the output has been pre-computed and can be loaded by calling data(EvoTraceR_object). 


<<example_analysis, eval=FALSE>>=
EvoTraceR_object = asv_analysis(EvoTraceR_object = EvoTraceR_object)
names(EvoTraceR_object)
@

There are new fields: 
clean_asv_dataframe which contains the counts detected for each ASV after filtering (i.e. after filtering for contamination identification of NMBC). 
reference is the information on the reference sequence considered for the analysis.
clean_asv_dataframe: ASV sequences identified post-filtering (contamination removed,
sequences with a similarity higher than \texttt{pid_cutoff_nmbc} to the original barcode
aggregated to it and ASVs named in increasing order (ASV01, ASV02, etc.) according
to their total counts. 
reference: Info about the reference sequence used for the current analysis. 
statistics: is a new list that contains all the results of the computation (see the manual for a detailed explanation). Among its fileds there are asv_df_percentages, which contains the normalized counts, and asv_diversity_perSample which contains the measures of clonal heterpgeneity. 
alignment: is a new list containing the result of the alignment step. 

<<example_mutationsProcessing, eval=FALSE>>=
# In case the previous two steps have not been run, users need to load the pre-computed EvoTraceR object:
# data(EvoTraceR_object)
EvoTraceR_object = analyse_mutations(EvoTraceR_object)
@

After alignment, EvoTraceR identifies, for each position in the original reference, the number of alterations found on the different ASVs. The final result is shown in figure gghist_del_sub_ins_perc.pdf which indicates for each position the frequency of the different mutations in each sample.
This computation stores the result in a new field mutations_df. 

<<example_phylogeny, eval=FALSE>>=
EvoTraceR_object = infer_phylogeny(EvoTraceR_object)
@

This function reconstructs the phylogenetic tree using the Cassiopeia's suite. 
It uses the greedy algorithm, that iteratively splits the set of ASVs in clusters
based on the most common mutation at each iteration.

<<example_create_df_summary, eval=FALSE>>=
EvoTraceR_object = create_df_summary(EvoTraceR_object)
@

Finally, this function combines in one dataframe all the data that have been computed for the phylogenetic analysis.


\section{\Rcode{sessionInfo()}}

<<sessioninfo,results='asis',echo=FALSE>>=
toLatex(sessionInfo())
@

\end{document}
