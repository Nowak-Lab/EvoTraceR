# This function initializes the EvoTraceR object, by computing the set of Amplicon Sequence Variants.
# It wraps all the steps performed by dada2, that are the following:
# (1) Filter and trimming reads.
# (2) Learning the error rates.
# (3) Dereplication.
# (4) Sample Inference.
# (5) Merging forward and reverse reads.
# (6) Construction of the Amplicon Sequence Variant table (ASV). 
# (7) Removal of chimeras.
# (8) [Optional] Production of a summary which tracks changes in the number of reads at every step of the pipeline.
# 
# For further information please refer to \href{https://benjjneb.github.io/dada2/tutorial_1_8.html}{the original vignette}.
# If users wish to manually run each step of dada2 computation they should execute all steps reported
# in the vignette, up to the Removal of chimeras and save the output of \code{removeBimeraDenovo} in a csv file and provide the path to that file as parameter \code{dada2_output_sequences}.
# 
# @title initialize_EvoTraceR
# 
# @examples
# input_dir = system.file("extdata", "input", package = "EvoTraceR")
# output_dir = system.file("extdata", "output", package = "EvoTraceR")
# initialize_EvoTraceR(input_dir = input_dir, output_dir = output_dir)
# 
# @param output_dir (Required). Path to the directory where all output files will be stored. The following \code{.csv} files will be created:
# \itemize{
# \item \code{quality_track_reads.csv}: track of the number of sequences during the 
# different steps of \code{dada2} analysis.
# \item \code{ dada2_asv_prefilter.csv}: sequences detected by dada2, with the counts detected in each sample.
# }
# @param input_dir Path to the directory containing \code{.fastq} files for forward and reverse reads.
# This folder should contain the fastq files (2 for each sample) with the following name pattern:
# FILEPREFIX_SAMPLE_BARCODEVERSION_R1.fastq FILEPREFIX_SAMPLE_BARCODEVERSION_R1.fastq. SAMPLE refers to either an organ (in case multiple organs were sequenced)
# or timepoint (if longitudinal data are provided). Note that EvoTraceR does not support mixed sample types (i.e. samples must be either all from organs or all from timepoints).
# Required when \code{dada2_output_sequences} is null (i.e. when the user has not previously run dada2).

# @param dada2_output_sequences (Optional). In case users have already run dada2 up to the removal of bimeras, they should provide the path to the csv file containing the output (See description).
# The output should contain samples on rows and sequences on columns.
# @param output_dir_dada2 (Optional). Output folder for dada2 filtered fastqs. If it doesn't exist it is created. Default is NULL and results in creating a 
# sub-folder in \code{output_folder} named 'filtered_fastq/'.
# @param random_seed (Optional). Seed for reproducibility. Deafult is NULL.
# @param output_figures (Optional). Boolean indicating whether or not to save intermediate dada2 plots such as read quality profiles.
# Deafult is \code{TRUE} and corresponds to creating a sub-folder inside \code{output_dir} named "dada2_figures".
# This folder will contain the following plots:
# \itemize{
# \item Quality profiles of both forward and reverse reads (generated by \code{dada2}).
# \item Error rates (generated by \code{dada2}).
# \item Histogram of sequences length.
# }
# @param multithread (Optional) default \code{TRUE}. Whether to enable multithreading. If TRUE the number of threads is determined automatically (dada2 functionality).
# If an integer is given, the number of threads is determined by its value.
# @param map_file_sample (Optional). In case fastq files names are not in the format \cr FILEPREFIX_SAMPLE_FILESUFFIX_RX.fastq),
# then users should provide a list that associates each filename (without the suffix _R1 and _R2) to the corresponding organ/day.
# (e.g., if we have forward and reverse files named file1_R1.fastq and file1_R2.fastq that correspond to organ PRL (code for Prostate Left), than the parameter should be set as: \code{map_file_sample = c("file1" = "PRL")}).
# @param dada2_pooled_analysis (Optional). Deafault = FALSE. Boolean that is passed to dada2 function \code{dada}, which performs sample inference.
# It can be set to TRUE in case of multiple samples coming from the same mouse (e.g. different organs or multiple time points) (See \href{https://benjjneb.github.io/dada2/pool.html}{here} for more information).
# @param dada2_chimeras_minFoldParentOverAbundance (Optional). Deafult = 8. parameter passed to the \code{dada2} function \code{isBimeraDenovo} during the call to \code{dada2 removeBimeraDenovo}. 
# @param verbose (Optional). Default TRUE. Boolean indicating whether or not to print the text output of dada2 functions.
# @param dada2_errorRate_estimation (Optional). Must be one of c('default', 'loessErrfun_mod1', 'loessErrfun_mod2', 'loessErrfun_mod3', 'loessErrfun_mod4').
# In case the fastq quality scores are in the range 0-40, keep the default option. The other 4 functions need to be used when dealing with NovaSeq data,
# where the quality scores in the fastq files are binned to only 4 different values. See \href{https://github.com/ErnakovichLab/dada2_ernakovichlab#learn-the-error-rates}{here} for more details.
# @param ... (Optional) Any additional parameters passed to \code{dada2} functions.
# 
# @return An object of type EvoTraceR, which is a list that will contain the following fields: 
# \itemize{
# \item \code{fastq_directory}: directory where the input fastq files are located.
# \item \code{output_directory}: directory where all the output files are being stored.
# \item \code{map_file_sample}: dataframe has as many rows as the input datasets, and for each input stores the sample (e.g. organ or day for longitudinal data)
# to which it is associated.
# \item \code{dada2_asv_prefilter}: dataframe that stores all sequences detected by \code{dada2}. Note that
# these sequences still need to be filtered (see also \code{\link{asv_analysis}}).
# \item \code{dada2}: list which contains the percentage of chimeras found by \code{dada2} and a dataframe
# that tracks the number of sequences during all \code{dada2} steps.
# }. This function also saves the following \code{.csv files} in the subfolder \code{dada2_files} created in the output dirctory provided by the user:
# \itemize{
# \item dada2_asv_prefilter.csv: sequences detected by dada2, with the counts detected in each sample.
# \item quality_track_reads.csv: track of the number of sequences during all \code{dada2} steps.
# }
# 
# @export initialize_EvoTraceR
# 
# @import dada2
# @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
# @rawNamespace import(dplyr, except = count)
# @importFrom cli cli_alert_info
# @importFrom utils write.csv read.csv unzip untar
# @importFrom grDevices cairo_pdf
# @importFrom stringr str_remove_all str_replace
initialize_EvoTraceR = function(output_dir,
                             input_dir = NULL,
                             dada2_output_sequences = NULL,
                             output_dir_dada2 = NULL,
                             random_seed = NULL,
                             output_figures = TRUE,
                             multithread = TRUE,
                             map_file_sample = NULL,
                             dada2_pooled_analysis = FALSE,
                             dada2_chimeras_minFoldParentOverAbundance = 8,
                             verbose = TRUE,
                             dada2_errorRate_estimation = 'default', 
                             ...) {
  # Check that the user inserted the correct parameters
  if (is.null(input_dir) & is.null(dada2_output_sequences)) {
    stop('Please provide either a directory containing fastqs for dada2 or the path to dada2 output')
  }
  if (is.null(output_dir)) {
    stop('Please provide a path where output files will be stored.')
  }
  
  if (! dada2_errorRate_estimation %in% c('default', 'loessErrfun_mod1', 'loessErrfun_mod2', 'loessErrfun_mod3', 'loessErrfun_mod4')) {
    stop("Parameter dada2_errorRate_estimation must be one of 'default', 'loessErrfun_mod1', 'loessErrfun_mod2', 'loessErrfun_mod3', 'loessErrfun_mod4'")
  }
  
  set.seed(random_seed)
  EvoTraceR_object = list(fastq_directory = input_dir, output_directory = output_dir)
  
  class(EvoTraceR_object) = 'EvoTraceR'
  EvoTraceR_object$dada2 = list()
  
  output_dir_files = file.path(output_dir, "dada2_files")
  if (!dir.exists(output_dir_files)) dir.create(output_dir_files, recursive = TRUE)
  
  if (is.null(dada2_output_sequences)) {
    # Fastq were provided as input -> perform alignment with dada2
    # Check if input files are compressed
    zip_files = list.files(input_dir, pattern = '.zip$', full.names = TRUE)
    tar_files = list.files(input_dir, pattern = '.tar$', full.names = TRUE)
    
    if (length(zip_files) > 0) {
      cli::cli_alert_info("Found zipped fastq files, extracting")
      for (zf in zip_files) {
        utils::unzip(zf, exdir = stringr::str_replace(input_dir, pattern = "/$", replacement=''))
      }
      cli::cli_alert_info("Done extracting")
    } else if (length(tar_files) > 0) {
      cli::cli_alert_info("Found tar fastq files, extracting")
      for (tf in tar_files) {
        utils::untar(tf, exdir = stringr::str_replace(input_dir, pattern = "/$", replacement=''))
      }
      cli::cli_alert_info("Done extracting")
    }
    fastqs = list.files(input_dir, pattern = '.fastq$')
    if (length(fastqs) == 0) {
      stop('No fastq files found in the input directory provided, stopping.')
    } else {
      cat("Found", length(fastqs), "fastq files")
    }
    fastqs = sort(fastqs) 
    fnFs = fastqs[grepl("_R1", fastqs)] 
    fnRs = fastqs[grepl("_R2", fastqs)] 
    # Get sample names, assuming files named as so: SAMPLENAME_XXX.fastq
    sample.names = stringr::str_remove_all(fnFs, "_R1.fastq")
    map_file_sample = check_input(sample.names = sample.names, 
                                  map_file_sample = map_file_sample)
    # Specify the full path to the fnFs and fnRs
    fnFs = file.path(input_dir, fnFs)
    fnRs = file.path(input_dir, fnRs)
    
    align_output = dada2_alignment(fnFs = fnFs,
                                   fnRs = fnRs,
                                   map_file_sample = map_file_sample,
                                   sample.names = sample.names,
                                   output_dir = output_dir,
                                   output_dir_files = output_dir_files,
                                   output_dir_dada2 = output_dir_dada2,
                                   output_figures = output_figures,
                                   multithread = multithread,
                                   dada2_pooled_analysis = dada2_pooled_analysis,
                                   verbose =  T,
                                   dada2_minFoldParentOverAbundance = dada2_chimeras_minFoldParentOverAbundance,
                                   dada2_errorRate_estimation = dada2_errorRate_estimation,
                                   ...)
    
    seqtab.nochim = align_output$seqtab.nochim
    EvoTraceR_object$dada2$track = align_output$track
    EvoTraceR_object$dada2$bimera_percentage = align_output$bimera_perc
    EvoTraceR_object$dada2$original_sequences = align_output$nSequences_with_chimeras
    
  } else {
    seqtab.nochim = utils::read.csv(dada2_output_sequences, 
                                    stringsAsFactors = FALSE,
                                    row.names = 1)
    map_file_sample = check_input(sample.names = rownames(seqtab.nochim), 
                                  map_file_sample = map_file_sample)
  }
  EvoTraceR_object$map_file_sample = map_file_sample
  EvoTraceR_object$dada2_asv_prefilter = adjust_seqtab(seqtab.nochim = seqtab.nochim,
                                                    map_file_sample = map_file_sample,
                                                    output_dir_files = output_dir_files)
  return(EvoTraceR_object)
  
}



# This function performs the analysis on ASV sequences identified by dada2 and aligns them to the reference sequence.
# First, it removes possible contamination sequences (ASVs resulting from other barcodes). 
# Then it performs pairwise alignment using Needleman-Wunsch global alignment algorithm implemented in function \code{pairwiseAlignment}
# in package \code{Biostrings}, aligning each sequence to the original barcode considered in the analysis 
# (See the Biostrings documentation \href{https://www.rdocumentation.org/packages/Biostrings/versions/2.40.2/topics/pairwiseAlignment}{here} for more details).
# Then it considers all those sequences exhibiting a similarity higher than \code{pid_cutoff_nmbc} with the original barcode as Non-Marking Guide Controls.
# Then, it computes different statistics for the ASVS, storing:
#  the relative frequency of all ASVs in each sample. 
#  the relative frequency of each ASV in the samples.
#  the counts for each ASV normalized to the counts of the sample with maximum frequency
#  the frequency of the different ASVs in each sample.
#  
# Finally, the ASVs that passed the previous filters are aligned again, either through multi-sequence alignment
# using the \href{https://bioconductor.org/packages/release/bioc/html/muscle.html}{MUSCLE} algorithm, or using the same 
# \code{pairwiseAlignment} function from \code{Biostrings} used to compute the similarity.
#  
# @title ASV_analysis
# 
# @examples
# data(revo_initialized)
# output_dir = system.file("extdata", "output", package = "EvoTraceR")
# revo_initialized$output_directory = output_dir
# revo_analyzed = asv_analysis(EvoTraceR_object = revo_initialized, )
# 
# @param EvoTraceR_object (Required). Object of class EvoTraceR, result of the function \code{initialize_EvoTraceR}
# @param ref_name String indicating the ID of the reference sequence used in the experiment. Default is 'BC10v0',
# @param ref_seq String indicating the reference sequence used in the experimenti. Default is 'TCTACACGCGCGTTCAACCGAGGAAAACTACACACACGTTCAACCACGGTTTTTTACACACGCATTCAACCACGGACTGCTACACACGCACTCAACCGTGGATATTTACATACTCGTTCAACCGTGGATTGTTACACCCGCGTTCAACCAGGGTCAGATACACCCACGTTCAACCGTGGTACTATACTCGGGCATTCAACCGCGGCTTTCTGCACACGCCTACAACCGCGGAACTATACACGTGCATTCACCCGTGGATC',
# @param ref_flank_left String indicating the first nucleotides of the reference sequence that never mutate over the
# course of the experiment. Default is "^TCTAC",
# @param ref_flank_right String indicating the first nucleotides of the reference sequence that never mutate over the
# course of the experiment. Default is "CCCGTGGATC$",
# @param flanking_filtering Which among the flaning regions to use to filter out contaminated sequences.
# Must be one of c('left', 'right', 'both', 'either'), default is 'both'
# @param ref_cut_sites Positions in the reference sequence of the cutting sites. Default is c(17, 42, 68, 94, 120, 146, 171, 198, 224, 251),
# @param ref_border_sites c(26, 52, 78, 104, 130, 156, 182, 208, 234).
# @param output_figures (Optional). Deafult TRUE: Boolean indicating whether a user whishes to store a figure indicating the number of ASV tracked during the different steps of the analysis.
# @param pid_cutoff_nmbc (Optional). Default to 98\%. Percentage of similarity between a sequence and the original barcode. The ASVs with a similarity obve this threshold will be considered as original non-mutated sequences in the analysis.
# @param asv_count_cutoff (Optional). Default to 2. Minimum number of counts for an ASV to be considered in the statistics.
# @param pwa_gapOpening (Optional). Delafult is -25. Parameter \code{gapOpening} passed to \code{pairwiseAlignment} from \code{Biostrings} (See description).
# @param pwa_gapExtension (Optional). Default is 0. Parameter \code{gapExtension} passed to \code{pairwiseAlignment} from \code{Biostrings} (See description). Default is 0.
# @param pwa_mismatch (Optional). Default is -4. Parameter indicating the penalty for mismatch events during pairwise alignment with \code{Biostrings}.
# @param pwa_match (Optional). Default is 15. Parameter indicating the score for matches during pairwise alignment with \code{Biostrings}. This parameter,
# together with the previous one, are used to construct the substitution matrix used by the function \code{pairwiseAlignment}.
# @param pwa_type (Optional). Parameter indicating the type of pairwise alignment. Must be one of One of "global", "local", "overlap", "global-local", and "local-global".
# For more details see \href{https://www.rdocumentation.org/packages/Biostrings/versions/2.40.2/topics/pairwiseAlignment}{original documentation} 
# @param compute_msa (Optional) Default is FALSE. If TRUE, multi-sequence alignment using muscle is performed on the ASVs.
# @param ... (Optional). Additional parameter passed to muscle.
# 
#
# @return  The EvoTraceR object passed as a parameter with the following new fields:
# \itemize{
# \item \code{clean_asv_dataframe}: ASV sequences identified post-filtering (contamination removed,
# sequences with a similarity higher than \code{pid_cutoff_nmbc} to the original barcode
# aggregated to it and ASVs named in increasing order (ASV01, ASV02, etc.) according
# to their total counts. 
# \item \code{reference}: Info about the reference sequence used for the current analysis.
#
#  \item \code{statistics}: another list with the following sub-fields: 
# \itemize{
# 
# \item \code{asv_df_percentages}: dataframe with six columns. \code{asv_names} is the name of the ASV.
# \code{sample} is the sample identifier (e.g. ID of an organ or, in case of longitudinal data, of the timepoint);
# \code{count}: total counts for a specific ASV in a specific sample;
# \code{perc_in_sample}: counts normalized to the total counts in the corresponding sample;
# \code{perc_asv}: counts normalized to the total counts for the corresponding ASV;
# \code{perc_fold_to_max}: counts normalized to the maximum counts observed for the corresponding ASV in a sample.
# 
# \item \code{asv_totalCounts}: for each ASV, total counts and number of samples in which it was detected.
# \item \code{sample_totalcounts}: for each sample, total counts and number of distinct ASVs detected.
# \item \code{asv_diversity_persample}: measures of clonal richness and measures of heterogeneity computed for each sample based on the ASVs detected.
# \item \code{asv_persample_frequency}: counts for each ASV in each sample.
# \item \code{asv_persample_detection}: binary matrix indicating whether a sequence has been detected in the corresponding sample.
# \item \code{asv_toBarcode_similarity}: edit distance, percentage similarity and alignment score of each ASV compared to the original barcode.
# \item \code{all_asv_statistics}: all the statistics computed on each ASV grouped together in the same tibble.
# }
# \item \code{alignment}, another list with the following fields:
# \itemize{
# \item \code{msa_stringset}: output of MSA performed with MUSCLE.
# \item \code{asv_barcode_alignment}: tibble where each line corresponds to a position in a ASV, and the columns encode the following information:
# \itemize{
# \item asv_names: name of the ASV
# \item sample: sample identifier
# \item position_bc260: position of the alteration in the original barcode. Note that insertions
# are assigned to the position that coincides with their beginning.
# \item alt: type of alteration. wt = Wild Type (i.e. non-mutated position). sub = substitution. del = deletion. ins = insertion.
# \item{ref_asv}, \item{read_asv}: respectively, the reference nucleotide observed in the original barcode and the one observed on the sequence.
# }
# }
# }
# 
# 
# It saves the following \code{.csv} files in a sub-folder \code{asv_analysis} of the main output folder:
# \itemize{
# \item \code{sequences_barcode_mapping.csv}: dataframe that stores, for each sequence,
# its counts in all samples. It also overwrites the sequence name (column seq_names) 
# of those that exactly match any of the possible barcodes, using the barcode identifier. The sequences
# that don't match the barcode in the current analysis may be due to contamination. 
# \item \code{clean_asv_dataframe.csv}, \code{asv_totalCounts.csv}, \code{sample_totalcounts.csv}, \code{asv_df_percentages.csv}, \code{asv_diversity_persample.csv}  
# \code{asv_persample_frequency.csv}, \item \code{asv_persample_detection.csv}, \code{asv_diversity_persample.csv} and \code{asv_toBarcode_similarity.csv}: content of the corresponding variables with the same name described above.
# 
# }
#  
# @export asv_analysis
#
# @importFrom Biostrings pairwiseAlignment pid nedit score nucleotideSubstitutionMatrix DNAStringSet
# @importFrom benthos total_abundance species_richness margalef rygg simpson hpie hill1 hill2 shannon
# @importFrom lemon coord_capped_cart facet_rep_grid
# @importFrom scales comma
# @importFrom utils write.csv
# @importFrom stringr str_detect
# @importFrom tidyr gather pivot_wider
# @importFrom forcats fct_relevel
# @importFrom data.table nafill
# @importFrom grDevices cairo_pdf
# @rawNamespace import(dplyr, except = count)
# @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
# @import tibble
# @import foreach
asv_analysis = function(EvoTraceR_object,
                        #barcode = 'BC10v0',
                        ref_name = 'BC10v0',
                        ref_seq = 'TCTACACGCGCGTTCAACCGAGGAAAACTACACACACGTTCAACCACGGTTTTTTACACACGCATTCAACCACGGACTGCTACACACGCACTCAACCGTGGATATTTACATACTCGTTCAACCGTGGATTGTTACACCCGCGTTCAACCAGGGTCAGATACACCCACGTTCAACCGTGGTACTATACTCGGGCATTCAACCGCGGCTTTCTGCACACGCCTACAACCGCGGAACTATACACGTGCATTCACCCGTGGATC',
                        ref_flank_left = "^TCTAC",
                        ref_flank_right = "CCCGTGGATC$",
                        flanking_filtering = 'right',
                        ref_cut_sites = c(17, 42, 68, 94, 120, 146, 171, 198, 224, 251),
                        ref_border_sites = c(1, 26, 52, 78, 104, 130, 156, 182, 208, 234),
                        output_figures = TRUE,
                        pid_cutoff_nmbc = 98,
                        asv_count_cutoff = 2,
                        pwa_gapOpening = -25,
                        pwa_gapExtension = 0,
                        pwa_match = 15,
                        pwa_mismatch = -4,
                        pwa_type = 'global',
                        compute_msa = FALSE,
                        ...) {
  
  if (output_figures) {
    figure_dir = file.path(EvoTraceR_object$output_directory, "asv_analysis_figures")
    if (!dir.exists(figure_dir)) dir.create(figure_dir)
  } else {
    figure_dir = NULL
  }
  output_dir = file.path(EvoTraceR_object$output_directory, "asv_analysis_files")
  if (!dir.exists(output_dir)) dir.create(output_dir)
  
  barcodes_info = list(
    ref_name = ref_name,
    ref_seq = ref_seq,
    ref_flank_left = ref_flank_left, # 5x nts
    ref_flank_right = ref_flank_right,
    ref_cut_sites = ref_cut_sites,
    ref_border_sites = ref_border_sites,
    stringsAsFactors = FALSE)
  
  seqtab_df = EvoTraceR_object$dada2_asv_prefilter
  
  EvoTraceR_object$reference = barcodes_info
  
  # Store the original number of sequences and that after chimeras removal
  orgseq <- EvoTraceR_object$dada2$original_sequences
  chimseq_filter <- nrow(seqtab_df)
  sample_columns = setdiff(colnames(seqtab_df), c("seq_names", "seq"))
  
  # Replace the seq-name for those sequences that match exactly one of the original barcodes.
  # In case no original barcode is found then insert it with 0 counts
  if (sum(seqtab_df$seq == barcodes_info$ref_seq) == 0){
    
    seqtab_df = seqtab_df %>% dplyr::add_row(seq_names = paste0(barcodes_info$ref_name, ".NMBC"), 
                                             seq = barcodes_info$ref_seq)
    seqtab_df[seqtab_df$seq_names == paste0(barcodes_info$ref_name, ".NMBC"), sample_columns] = 0
    
  } else {
    seqtab_df[seqtab_df$seq == barcodes_info$ref_seq, "seq_names"] = paste0(barcodes_info$ref_name, ".NMBC")
  }
  
  
  seqtab_df_original = seqtab_df
  # Removal of contamination: keep only those ASV that start (5 nucleotides) and end (10 nuceotides) like the original barcode.
  # The first 5 nts are the same for all barcodes, while the end is barcode-specific
  RD1_10 <- barcodes_info$ref_flank_left
  RD2_10 <- barcodes_info$ref_flank_right
  nmbc <- paste0(ref_name, ".NMBC")#gsub(pattern = 'ORG', replacement = 'NMBC', x=barcode)
  # filter based on 5' and 3' 10x nts of
  if (flanking_filtering == 'both') {
    seqtab_df <- dplyr::filter(seqtab_df,
                               stringr::str_detect(string = seq, pattern = !!RD1_10) & stringr::str_detect(string = seq, pattern = !!RD2_10)) # the same for different barcodes: 1.0 - site less affected
    
  } else if (flanking_filtering == 'right') {
    seqtab_df <- dplyr::filter(seqtab_df,
                               stringr::str_detect(string = seq, pattern = !!RD2_10)) # the same for different barcodes: 1.0 - site less affected
    
  } else if(flanking_filtering == 'left') {
    seqtab_df <- dplyr::filter(seqtab_df,
                               stringr::str_detect(string = seq, pattern = !!RD1_10)) # the same for different barcodes: 1.0 - site less affected
    
  } else if (flanking_filtering == 'either'){
    seqtab_df <- dplyr::filter(seqtab_df,
                               stringr::str_detect(string = seq, pattern = !!RD1_10) | stringr::str_detect(string = seq, pattern = !!RD2_10)) # the same for different barcodes: 1.0 - site less a
  } else {
    stop('Flanking filtering must be one of "left", "right", "both" or "either". Exiting.')
  }
  
  seqtab_df_original$condition = 'removed'
  seqtab_df_original[rownames(seqtab_df_original) %in% rownames(seqtab_df),]$condition = 'kept'
  seqtab_df_original$total_counts = rowSums(seqtab_df_original[,sample_columns])
  
  seqtab_df_original$condition = as.factor(seqtab_df_original$condition)
  
  # ggplot(seqtab_df_original[seqtab_df_original$seq_names != "BC10v0.NMBC",], 
  #        aes(x = total_counts, fill = condition)) +                       # Draw overlaying histogram
  #   geom_histogram(position = "identity", bins = 20, alpha=0.5) + scale_x_log10()
  
  
  endseq_filter <- nrow(seqtab_df)
  
  mx_crispr <- Biostrings::nucleotideSubstitutionMatrix(match = pwa_match, mismatch = pwa_mismatch, baseOnly = TRUE)
  
  pwa <- Biostrings::pairwiseAlignment(subject = barcodes_info$ref_seq, 
                                       pattern = seqtab_df$seq, 
                                       substitutionMatrix = mx_crispr,
                                       gapOpening = pwa_gapOpening,
                                       gapExtension = pwa_gapExtension,
                                       type = pwa_type)
  # Compute the percent sequence identity
  seqtab_df$pid <- Biostrings::pid(pwa)
  
  # Assign to each ASV with pid >= cutoff the original barcode and then pool the sequences
  # (the counts of each ASV with pid >= cutoff will be summed to the ones of the NMBC)
  pidseq_filter = seqtab_df %>% 
    mutate(seq_names = ifelse(pid >= pid_cutoff_nmbc, nmbc, seq_names)) %>%
    dplyr::select(seq_names, all_of(sample_columns), pid) %>%
    group_by(seq_names) %>%
    dplyr::summarise_at(sample_columns, sum) %>%
    merge(dplyr:: select(seqtab_df, seq_names, seq), by = "seq_names")
  pidseq_filter_dim = nrow(pidseq_filter)
  
  # Now sort ASV by total frequency and assign an ASV ID
  seqtab_df_clean_asv <-
    tibble(pidseq_filter) %>%
    mutate(asv_total_freq = rowSums(across(where(is.numeric)))) %>%
    arrange(-asv_total_freq)  %>%
    mutate(asv_names = seq_names)
  # Find Row for NMBC
  seqtab_df_clean_nmbc <- seqtab_df_clean_asv[stringr::str_detect(string = seqtab_df_clean_asv$seq_names, pattern = "NMBC"),]
  
  # skip NMBC
  seqtab_df_clean_asv <-
    seqtab_df_clean_asv %>%
    filter(!stringr::str_detect(string = seq_names, pattern = "NMBC")) 
  # create ASV count
  seqtab_df_clean_asv$asv_names <- paste0("ASV", 
                                          formatC(c(1:nrow(seqtab_df_clean_asv)), 
                                                  width = nchar(trunc(nrow(seqtab_df_clean_asv))), 
                                                  format = "d", flag = "0")) # -1 to start 00 with no changes sequence
  # add back row with "seqtab_df_perf_match"  
  seqtab_df_clean_asv <-
    seqtab_df_clean_asv %>%
    add_row(seqtab_df_clean_nmbc) %>%
    arrange(-asv_total_freq) %>%
    dplyr::select(-c("seq_names", "asv_total_freq")) %>%
    relocate(asv_names)
  # final number of ASVs for analysis
  clean_asv <- nrow(seqtab_df_clean_asv)
  # save csv with final ASvs
  utils::write.csv(seqtab_df_clean_asv, file.path(output_dir, "/clean_asv_dataframe.csv"), row.names = F)
  
  
  EvoTraceR_object$clean_asv_dataframe = seqtab_df_clean_asv
  
  norm_seqtab_df_clean_asv = seqtab_df_clean_asv
  norm_seqtab_df_clean_asv[,sample_columns] = sweep(norm_seqtab_df_clean_asv[, sample_columns], 2, 
                                                    EvoTraceR_object$dada2$track[sample_columns,'input'], '/') 
  
  # norm_seqtab_df_clean_asv[,sample_columns] = sapply(sweep(norm_seqtab_df_clean_asv[, sample_columns], 2, 
  #                                                          EvoTraceR_object$dada2$track[sample_columns,'input'], '/') * 1e6, as.integer)
  
  norm_seqtab_df_clean_asv[sample_columns] <- norm_seqtab_df_clean_asv[sample_columns]
  
  EvoTraceR_object$clean_asv_dataframe_countnorm = norm_seqtab_df_clean_asv
  
  utils::write.csv(norm_seqtab_df_clean_asv, 
                   file.path(output_dir, "/clean_asv_dataframe_countnorm.csv"), 
                   row.names = F)
  
  EvoTraceR_object = asv_statistics(EvoTraceR_object, 
                                 sample_columns, 
                                 asv_count_cutoff,
                                 figure_dir,
                                 nmbc,
                                 output_dir = output_dir)
  
  
  if(output_figures) {
    # assemble data  with all number for each step of filtering
    track_data <- data.frame(name=as.factor(c("Starting ASVs", "Chimeric Seq. Filter", "Flanking Seq. Filter", "Similarity Seq. Filter", "Final ASVs")), num=c(orgseq, chimseq_filter, endseq_filter, pidseq_filter_dim, clean_asv))
    # set order of columns DGN
    track_data <- dplyr::mutate(track_data, name = fct_relevel(name, c("Starting ASVs", "Chimeric Seq. Filter", "Flanking Seq. Filter", "Similarity Seq. Filter", "Final ASVs")))
    track_data$num_names <- paste0(track_data$num, " x ASVs") # numbers of ASV included on the top of bar  
    
    # calculate percent change from previous filter
    track_data <-
      track_data %>%
      mutate(track_data, diff_perc = ceiling(x=(num/lag(num)-1)*100)) %>%
      mutate(diff_perc = paste0(diff_perc, " %")) %>%
      mutate(diff_perc = if_else(name == "Starting ASVs" | name == "Final ASVs", "", diff_perc)) %>%
      mutate(num_names_sf = if_else(name == "Starting ASVs" | name == "Final ASVs", num_names, "")) %>%
      mutate(num_names_ins = if_else(name == "Starting ASVs" | name == "Final ASVs", "", num_names))
    
    # start graph plotting 
    seqtab_df_clean_track <-
      ggplot(data=track_data) +
      geom_bar(aes(x=name, y=num, fill=name), position = "dodge", stat = "identity", width=0.8, size=0.2, show.legend = FALSE) +
      geom_text(aes(x=name, y=num, label=num_names_sf), vjust=-0.25, size=3) + # change order to have up whatever you choose, opposite to order
      geom_text(aes(x=name, y=num, label=num_names_ins), vjust=-1.75, size=3) + # change order to have up whatever you choose, opposite to order
      geom_text(aes(x=name, y=num, label=diff_perc), vjust=-0.25, size=3, col="blue") + # change order to have up whatever you choose, opposite to order
      scale_y_continuous(expand = c(0, 0), 
                         limits= c(0, plyr::round_any(max(track_data$num), 100, f = ceiling)+100/4), 
                         breaks = seq(0, (plyr::round_any(max(track_data$num), 100, f = ceiling)), 100)) +
      scale_fill_manual(values=c("#444c5c", "#aaaaaa", "#aaaaaa", "#aaaaaa", "#78a5a3")) +
      labs(x = "ASVs Filtering Steps", y = "Number of ASVs") + 
      lemon::coord_capped_cart(left="both") + # axis with lemon
      barplot_nowaklab_theme() + # add theme 
      theme(plot.margin = unit(c(0, 0, 0, 0), "mm"), # update theme specifically 
            axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), # , hjust = 1, vjust = 1
            axis.line.x = element_blank(), # disable x axis lines
            axis.ticks.x = element_blank()) # disable x axis ticks lines
    # save pdf
    ggsave(filename=file.path(figure_dir, "track_asv_number.pdf"), plot=seqtab_df_clean_track, width=15, height=15, units = "cm")
    # save csv
    write.csv(track_data, file.path(figure_dir, "/track_asv_number_data.csv"), row.names = FALSE, quote = FALSE)
  }
  output_dir_files_alignment = file.path(EvoTraceR_object$output_directory, "alignment")
  if(!dir.exists(output_dir_files_alignment)) dir.create(output_dir_files_alignment)
  
  output_dir_figures_alignment = file.path(EvoTraceR_object$output_directory, "alignment_figures")
  if (!dir.exists(output_dir_figures_alignment)) {dir.create(output_dir_figures_alignment)}
  
  
  EvoTraceR_object = align_asv(EvoTraceR_object, 
                            pwa_match= pwa_match,
                            pwa_mismatch = pwa_mismatch,
                            pwa_gapOpening = pwa_gapOpening,
                            pwa_gapExtension = pwa_gapExtension,
                            output_dir_files = output_dir_files_alignment, 
                            output_dir_figures = output_dir_figures_alignment,
                            pwa_type = pwa_type,
                            compute_msa = compute_msa,
                            ...)
  
  return(EvoTraceR_object)
  
}

