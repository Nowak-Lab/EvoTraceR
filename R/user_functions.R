#' This function initializes the REvoBC object, by computing the set of Amplicon Sequence Variants.
#' It wraps all the steps performed by dada2, that are the following:
#' (1) Filter and trimming reads.
#' (2) Learning the error rates.
#' (3) Dereplication.
#' (4) Sample Inference.
#' (5) Merging forward and reverse reads.
#' (6) Construction of the Amplicon Sequence Variant table (ASV). 
#' (7) Removal of chimeras.
#' (8) [Optional] Production of a summary which tracks changes in the number of reads at every step of the pipeline.
#' 
#' For further information please refer to \href{https://benjjneb.github.io/dada2/tutorial_1_8.html}{the original vignette}.
#' If users wish to manually run each step of dada2 computation they should execute all steps reported
#' in the vignette, up to the Removal of chimeras and save the output of \code{removeBimeraDenovo} in a csv file and provide the path to that file as parameter \code{dada2_output_sequences}.
#' 
#' @title initialize_REvoBC
#' 
#' @examples
#' input_dir = system.file("extdata", "input", package = "REvoBC")
#' output_dir = system.file("extdata", "output", package = "REvoBC")
#' initialize_REvoBC(input_dir = input_dir, output_dir = output_dir)
#' 
#' @param output_dir (Required). Path to the directory where all output files will be stored. The following \code{.csv} files will be created:
#' \itemize{
#' \item \code{quality_track_reads.csv}: track of the number of sequences during the 
#' different stepsof \code{dada2} analysis.
#' \item \code{ dada2_asv_prefilter.csv}: sequences detected by dada2, with the counts detected in each sample.
#' }
#' @param input_dir Path to the directory containing \code{.fastq} files for forward and reverse reads.
#' This folder should contain the fastq files (2 for each sample) with the following name pattern:
#' FILEPREFIX_SAMPLE_BARCODEVERSION_R1.fastq FILEPREFIX_SAMPLE_BARCODEVERSION_R1.fastq. SAMPLE refers to either an organ (in case multiple organs were sequenced)
#' or timepoint (if longitudinal data are provided). Note that REvoBC does not support mixed sample types (i.e. samples must be either all from organs or all from timepoints).
#' Required when \code{dada2_output_sequences} is null (i.e. when the user has not previously run dada2).

#' @param dada2_output_sequences (Optional). In case users have already run dada2 up to the removal of bimeras, they should provide the path to the csv file containing the output (See description).
#' The output should contain samples on rows and sequences on columns.
#' @param output_dir_dada2 (Optional). Output folder for dada2 filtered fastqs. If it doesn't exist it is created. Default is NULL and results in creating a 
#' sub-folder in \code{output_folder} named 'filtered_fastq/'.
#' @param random_seed (Optional). Seed for reproducibility. Deafult is NULL.
#' @param output_figures (Optional). Boolean indicating whether or not to save intermediate dada2 plots such as read quality profiles.
#' Deafult is \code{TRUE} and corresponds to creating a sub-folder inside \code{output_dir} named "dada2_plots".
#' This folder will contain the following plots:
#' \itemize{
#' \item Quality profiles of both forward and reverse reads (generated by \code{dada2}).
#' \item Error rates (generated by \code{dada2}).
#' \item Histogram of sequences length.
#' }
#' @param multithread (Optional) default \code{TRUE}. Whether to enable multithreading. If TRUE the number of threads is determined automatically (dada2 functionality).
#' If an integer is given, the number of threads is determined by its value.
#' @param map_file_sample (Optional). In case fastq files names are not in the format \cr FILEPREFIX_SAMPLE_FILESUFFIX_RX.fastq),
#' then users should provide a list that associates each filename (without the suffix _R1 and _R2) to the corresponding organ/day.
#' (e.g., if we have forward and reverse files named file1_R1.fastq and file1_R2.fastq that correspond to organ PRL (code for Prostate Left), than the parameter should be set as: \code{map_file_sample = c("file1" = "PRL")}).
#' @param dada2_pooled_analysis (Optional). Deafault = FALSE. Boolean that is passed to dada2 function \code{dada}, which performs sample inference.
#' It can be set to TRUE in case of multiple samples coming from the same mouse (e.g. different organs or multiple time points) (See \href{https://benjjneb.github.io/dada2/pool.html}{here} for more information).
#' @param dada2_chimeras_minFoldParentOverAbundance (Optional). Deafult = 8. parameter passed to the \code{dada2} function \code{isBimeraDenovo} during the call to \code{dada2 removeBimeraDenovo}. 
#' @param verbose (Optional). Default TRUE. Boolean indicating whether or not to print the text output of dada2 functions.
#' @param ... (Optional) Any additional parameters passed to \code{dada2} functions.
#' 
#' @return An object of type REvoBC, which is a list that will contain the following fields: 
#' \itemize{
#' \item \code{fastq_directory}: directory where the input fastq files are located.
#' \item \code{output_directory}: directory where all the output files are being stored.
#' \item \code{map_file_sample}: dataframe has as many rows as the input datasets, and for each input stores the sample (e.g. organ or day for longitudinal data)
#' to which it is associated.
#' \item \code{dada2_asv_prefilter}: dataframe that stores all sequences detected by \code{dada2}. Note that
#' these sequences still need to be filtered (see also \code{\link{asv_analysis}}).
#' \item \code{dada2}: list which contains the percentage of chimeras found by \code{dada2} and a dataframe
#' that tracks the number of sequences during all \code{dada2} steps.
#' }. This function also saves the following \code{.csv files} in the subfolder \code{dada2_files} created in the output dirctory provided by the user:
#' \itemize{
#' \item dada2_asv_prefilter.csv: sequences detected by dada2, with the counts detected in each sample.
#' \item quality_track_reads.csv: track of the number of sequences during all \code{dada2} steps.
#' }
#' 
#' @export initialize_REvoBC
#' 
#' @import dada2
#' @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
#' @rawNamespace import(dplyr, except = count)
#' @importFrom cli cli_alert_info
#' @importFrom utils write.csv read.csv unzip untar
# @importFrom grDevices cairo_pdf
#' @importFrom stringr str_remove_all str_replace
initialize_REvoBC = function( output_dir,
                              input_dir = NULL,
                              dada2_output_sequences = NULL,
                              output_dir_dada2 = NULL,
                              random_seed = NULL,
                              output_figures = TRUE,
                              multithread = TRUE,
                              map_file_sample = NULL,
                              dada2_pooled_analysis = FALSE,
                              dada2_chimeras_minFoldParentOverAbundance = 8,
                              verbose = TRUE,
                              ...) {
  # Check that the user inserted the correct parameters
  if (is.null(input_dir) & is.null(dada2_output_sequences)) {
    stop('Please provide either a directory containing fastqs for dada2 or the path to dada2 output')
  }
  if (is.null(output_dir)) {
    stop('Please provide a path where output files will be stored.')
  }

  set.seed(random_seed)
  REvoBC_object = list(fastq_directory = input_dir, output_directory = output_dir)
  
  class(REvoBC_object) = 'REvoBC'
  REvoBC_object$dada2 = list()
  
  output_dir_files = file.path(output_dir, "dada2_files")
  if (!dir.exists(output_dir_files)) dir.create(output_dir_files)
  
  if (is.null(dada2_output_sequences)) {
    # Fastq were provided as input -> perform alignment with dada2
    # Check if input files are compressed
    zip_files = list.files(input_dir, pattern = '.zip$', full.names = T)
    tar_files = list.files(input_dir, pattern = '.tar$', full.names = T)
    
    if (length(zip_files) > 0) {
      cli::cli_alert_info("Found zipped fastq files, extracting")
      for (zf in zip_files) {
        utils::unzip(zf, exdir = stringr::str_replace(input_dir, pattern = "/$", replacement=''))
      }
      cli::cli_alert_info("Done extracting")
    } else if (length(tar_files) > 0) {
      cli::cli_alert_info("Found tar fastq files, extracting")
      for (tf in tar_files) {
        utils::untar(tf, exdir = stringr::str_replace(input_dir, pattern = "/$", replacement=''))
      }
      cli::cli_alert_info("Done extracting")
    }
    fastqs = list.files(input_dir, pattern = '.fastq$')
    if (length(fastqs) == 0) {
      stop('No fastq files found in the input directory provided, stopping.')
    } else {
      cat("Found", length(fastqs), "fastq files")
    }
    fastqs = sort(fastqs) 
    fnFs = fastqs[grepl("_R1", fastqs)] 
    fnRs = fastqs[grepl("_R2", fastqs)] 
    # Get sample names, assuming files named as so: SAMPLENAME_XXX.fastq
    sample.names = stringr::str_remove_all(fnFs, "_R1.fastq")
    map_file_sample = check_input(sample.names = sample.names, 
                                   map_file_sample = map_file_sample)
    # Specify the full path to the fnFs and fnRs
    fnFs = file.path(input_dir, fnFs)
    fnRs = file.path(input_dir, fnRs)
    
    align_output = dada2_alignment(fnFs = fnFs,
                                   fnRs = fnRs,
                                   map_file_sample = map_file_sample,
                                   sample.names = sample.names,
                                   output_dir = output_dir,
                                   output_dir_files = output_dir_files,
                                   output_dir_dada2 = output_dir_dada2,
                                   output_figures = output_figures,
                                   multithread = multithread,
                                   dada2_pooled_analysis = dada2_pooled_analysis,
                                   verbose =  T,
                                   dada2_minFoldParentOverAbundance = dada2_chimeras_minFoldParentOverAbundance,
                                   ...)
    
    seqtab.nochim = align_output$seqtab.nochim
    REvoBC_object$dada2$track = align_output$track
    REvoBC_object$dada2$bimera_percentage = align_output$bimera_perc
    REvoBC_object$dada2$original_sequences = align_output$nSequences_with_chimeras
    
  } else {
    seqtab.nochim = utils::read.csv(dada2_output_sequences, 
                             stringsAsFactors = FALSE,
                             row.names = 1)
    map_file_sample = check_input(sample.names = rownames(seqtab.nochim), 
                                   map_file_sample = map_file_sample)
  }
  REvoBC_object$map_file_sample = map_file_sample
  REvoBC_object$dada2_asv_prefilter = adjust_seqtab(seqtab.nochim = seqtab.nochim,
                                                    map_file_sample = map_file_sample,
                                                    output_dir_files = output_dir_files)
  return(REvoBC_object)
  
}

#' This function performs the analysis on ASV sequences identified by dada2.
#' First, it removes possible contamination sequences (ASVs resulting from other barcodes). 
#' Then it performs pairwise alignment using Needleman-Wunsch global alignment algorithm implemented in function \code{pairwiseAlignment}
#' in package \code{Biostrings}, aligning each sequence to the original barcode considered in the analysis 
#' (See the Biostrings documentation \href{https://www.rdocumentation.org/packages/Biostrings/versions/2.40.2/topics/pairwiseAlignment}{here} for more details).
#' Then it considers all those sequences exhibiting a similarity higher than \code{pid_cutoff_nmbc} with the original barcode as Non-Marking Guide Controls.
#' Finally, it computes different statistics for the ASVS, storing:
#'  the relative frequency of all ASVs in each sample. 
#'  the relative frequency of each ASV in the samples.
#'  the counts for each ASV normalized to the counts of the sample with maximum frequency
#'  the frequency of the different ASVs in each sample.
#'  
#' @title ASV_analysis
#' 
#' @examples
#' data(revo_initialized)
#' output_dir = system.file("extdata", "output", package = "REvoBC")
#' revo_initialized$output_directory = output_dir
#' revo_analyzed = asv_analysis(REvoBC_object = revo_initialized, barcode = 'BC10v0')
#' 
#' @param REvoBC_object (Required). Object of class REvoBC, result of the function \code{initialize_REvoBC}
#' @param barcode (Required). String indicating the barcode used in the experiment.
#' @param output_figures (Optional). Deafult TRUE: Boolean indicating whether a user whishes to store a figure indicating the number of ASV tracked during the different steps of the analysis.
#' @param pid_cutoff_nmbc (Optional). Default to 98\%. Percentage of similarity between a sequence and the original barcode. The ASVs with a similarity obve this threshold will be considered as original non-mutated sequences in the analysis.
#' @param asv_count_cutoff (Optional). Default to 2. Minimum number of counts for an ASV to be considered in the statistics.
#' @param ... Any additional parameters passed to \code{pairwiseAlignment} from \code{Biostrings} (See description).
#'
#' @return  The REvoBC object passed as a parameter with the following new fields:
#' \itemize{
#' \item \code{clean_asv_dataframe}: ASV sequences identified post-filtering (contamination removed,
#' sequences with a similarity higher than \code{pid_cutoff_nmbc} to the original barcode
#' aggregated to it and ASVs named in increasing order (ASV01, ASV02, etc.) according
#' to their total counts. 
#' \item \code{barcode}: Info about the barcode selected for the current analysis.
#'
#'  \item \code{statistics}: another list with the following sub-fileds: 
#' \itemize{
#' 
#' \item \code{asv_df_percentages}: dataframe with six columns. \code{asv_names} is the name of the ASV.
#' \code{sample} is the sample identifier (e.g. ID of an organ or, in case of longitudinal data, of the timepoint);
#' \code{count}: total counts for a specific ASV in a specific sample;
#' \code{perc_in_sample}: counts normalized to the total counts in the corresponding sample;
#' \code{perc_asv}: counts normalized to the total counts for the corresponding ASV;
#' \code{perc_fold_to_max}: counts normalized to the maximum counts observed for the corresponding ASV in a sample.
#' 
#' \item \code{asv_totalCounts}: for each ASV, total counts and number of samples in which it was detected.
#' \item \code{sample_totalcounts}: for each sample, total counts and number of distinct ASVs detected.
#' \item \code{asv_diversity_persample}: measures of clonal richness and measures of heterogeneity computed for each sample based on the ASVs detected.
#' \item \code{asv_persample_frequency}: counts for each ASV in each sample.
#' \item \code{asv_persample_detection}: binary matrix indicating whether a sequence has been detected in the corresponding sample.
#' \item \code{asv_toBarcode_similarity}: edit distance, percentage similarity and alignment score of each ASV compared to the original barcode.
#' \item \code{all_asv_statistics}: all the statistics computed on each ASV grouped toghether in the same tibble.
#' }
#' }  
#' 
#' It saves the following \code{.csv} files in a sub-folder \code{asv_analysis} of the main output folder:
#' \itemize{
#' \item \code{sequences_barcode_mapping.csv}: dataframe that stores, for each sequence,
#' its counts in all samples. It also overwrites the sequence name (column seq_names) 
#' of those that exactly match any of the possible barcodes, using the barcode identifier. The sequences
#' that don't match the barcode in the current analysis may be due to contamination. 
#' \item \code{clean_asv_dataframe.csv}, \code{asv_totalCounts.csv}, \code{sample_totalcounts.csv}, \code{asv_df_percentages.csv}, \code{asv_diversity_persample.csv}  
#' \code{asv_persample_frequency.csv}, \item \code{asv_persample_detection.csv}, \code{asv_diversity_persample.csv} and \code{asv_toBarcode_similarity.csv}: content of the corresponding variables with the same name described above.
#' 
#' }
#'  
#' @export asv_analysis
#'
#' @importFrom Biostrings pairwiseAlignment pid nedit score
#' @importFrom benthos total_abundance species_richness margalef rygg simpson hpie hill1 hill2 shannon
#' @importFrom lemon coord_capped_cart facet_rep_grid
#' @importFrom scales comma
#' @importFrom utils write.csv
#' @importFrom stringr str_detect
#' @importFrom tidyr gather pivot_wider
#' @importFrom forcats fct_relevel
#' @importFrom data.table nafill
# @importFrom grDevices cairo_pdf
#' @rawNamespace import(dplyr, except = count)
#' @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
#' @import tibble
asv_analysis = function(REvoBC_object,
                        barcode = 'BC10v0',
                        output_figures = TRUE,
                        pid_cutoff_nmbc = 98,
                        asv_count_cutoff = 2,
                        ...) {
  dots = list(...)
  if (output_figures) {
    figure_dir = file.path(REvoBC_object$output_directory, "asv_analysis_figures")
    if (!dir.exists(figure_dir)) dir.create(figure_dir)
  } else {
    figure_dir = NULL
  }
  output_dir = file.path(REvoBC_object$output_directory, "asv_analysis")
  if (!dir.exists(output_dir)) dir.create(output_dir)
  
  barcodes_info = data.frame(
    asv_names = c("BC10v0", "BC10v1", "BC10v2", "BC10v3", "BC10v4"),
    seq_start = c("^TCTAC", "^TCTAC", "^TCTAC", "^TCTAC", "^TCTAC"), # 5x nts
    seq_end = c("CCCGTGGATC$", "GCCGGGGATC$", "ACCGGGGATC$", "ACCCTGGATC$", "GCCGCGGATC$"),
    seq = c("TCTACACGCGCGTTCAACCGAGGAAAACTACACACACGTTCAACCACGGTTTTTTACACACGCATTCAACCACGGACTGCTACACACGCACTCAACCGTGGATATTTACATACTCGTTCAACCGTGGATTGTTACACCCGCGTTCAACCAGGGTCAGATACACCCACGTTCAACCGTGGTACTATACTCGGGCATTCAACCGCGGCTTTCTGCACACGCCTACAACCGCGGAACTATACACGTGCATTCACCCGTGGATC",
            "TCTACACGCGCGTTCAACCGAGGAAAACTACACACACGTTCAACCACGGTTTGTTACACACGCATTCAACCGCGGACTATTACACGCTCGTTCAACCAGGGATATTTACACGCAAGTTCAACCACGGATTTATACACGCGCACTCAACCAGGGTCATCTACGCAAGCGTTCAATCGAGGTACATTCCACGCGCATTCAACCGGGGCTTTTTACACCCGCGCTCAACAGGGGAACTTTACACGTGCGATCAGCCGGGGATC",
            "TCTACACGCGCGTTCAACCGAGGAAAACTACACACGCATTCAACCACGGTTTATTACACGCACATTCAACCGTGGACTGCTACACACGCGCTCAACCACGGATATTTACGCACACGTTCAACCGCGGATTGTTACACCCGCATTCAACCGAGGTCACCTACACCCGCACTCAACCGGGGTACGCGACACGTGCGATCAACCGAGGCTTACTACCCGCACGTTCAACTGGGGAACACTGCACGCGAGTTCGACCGGGGATC",
            "TCTACACGCGCGTTCAACCGAGGAAAACTACACACACATTCAACCGTGGTTTACTACACAAGCGTTCAACCAAGGACTCCTACACATACGTTCAACCGTGGATATTTACACGTTCGTTCAACCAGGGATTTTTACAAACGAGTTCAACCGGGGTCACTTATACGCTCGTTCAACCGAGGTACTCTACACGCACCTTCAATCACGGCTTCCTACAGGAGCGTTCAAACGCGGAACTCAACGGGCGCGTTCAACCCTGGATC",
            "TCTACACGCGCGTTCAACCGAGGAAAACTACACACACATTCAACCGTGGTTTATTACACGCACGTTCAACCAGGGACTTTTACATACGCATTCAACCGGGGATATTTACTCACACGTTCAACCGGGGATTGCTACACGAACGTTCAATCGCGGTCATCAACGTGCGCATTCAACCGTGGTACACTACGCACCCGTTCAACCGGGGCTTTGGACACGCGCATACAACCGTGGAACTCTACACAGGCATTCAGCCGCGGATC"),
    stringsAsFactors = FALSE)
  
  if(!barcode %in% barcodes_info$asv_names) {
    stop("The barcode provided doesn't match any of the possible ones, exiting")
  }
  
  seqtab_df = REvoBC_object$dada2_asv_prefilter
  
  REvoBC_object$barcode = barcodes_info[barcodes_info$asv_names == barcode,]
  
  # Store the original number of sequences and that after chimeras removal
  orgseq <- REvoBC_object$dada2$original_sequences
  chimseq_filter <- nrow(seqtab_df)
  sample_columns = setdiff(colnames(seqtab_df), c("seq_names", "seq"))
  
  # Replace the seq-name for those sequences that match exactly one of the original barcodes.
  match_seq = match(seqtab_df$seq, barcodes_info$seq)
  barcodes_idx = match_seq[!is.na(match_seq)]
  seqtab_df$seq_names[!is.na(match_seq)] = paste0(barcodes_info$asv_names[barcodes_idx], ".NMBC")
  #gsub(pattern = '.ORG',replacement = '.NMBC', x = barcodes_info$asv_names[barcodes_idx])
  seqtab_df_original = seqtab_df
  utils::write.csv(seqtab_df,
            file.path(output_dir,
                      "sequences_barcode_mapping.csv"),
            row.names = FALSE)
  
  # Removal of contamination: keep only those ASV that start (5 nucleotides) and end (10 nuceotides) like the original barcode.
  # The first 5 nts are the same for all barcodes, while the end is barcode-specific
  RD1_10 <- barcodes_info[barcodes_info$asv_names == barcode, 'seq_start']# as.character(dplyr::select(filter(bc_ver, asv_names == bc10_org), seq_start))
  RD2_10 <- barcodes_info[barcodes_info$asv_names == barcode, 'seq_end']
  nmbc <- paste0(barcode, ".NMBC")#gsub(pattern = 'ORG', replacement = 'NMBC', x=barcode)
  # filter based on 5' and 3' 10x nts of 
  seqtab_df <- dplyr::filter(seqtab_df, 
                             stringr::str_detect(string = seq, pattern = RD1_10) & stringr::str_detect(string = seq, pattern = RD2_10)) # the same for different barcodes: 1.0 - site less affected
  
  seqtab_df_original$condition = 'removed'
  seqtab_df_original[rownames(seqtab_df_original) %in% rownames(seqtab_df),]$condition = 'kept'
  seqtab_df_original$total_counts = rowSums(seqtab_df_original[,sample_columns])
  
  seqtab_df_original$condition = as.factor(seqtab_df_original$condition)
  
  # ggplot(seqtab_df_original[seqtab_df_original$seq_names != "BC10v0.NMBC",], 
  #        aes(x = total_counts, fill = condition)) +                       # Draw overlaying histogram
  #   geom_histogram(position = "identity", bins = 20, alpha=0.5) + scale_x_log10()
  
  
  endseq_filter <- nrow(seqtab_df)
  
  pwa <- do.call(Biostrings::pairwiseAlignment, 
                 c(list(subject = barcodes_info[barcodes_info$asv_names == barcode, 'seq'], 
                        pattern = seqtab_df$seq, 
                        type="global"),
                   get_args_from_dots(dots, Biostrings::pairwiseAlignment)))
  # Compute the percent sequence identity
  seqtab_df$pid <- Biostrings::pid(pwa)
  
  # Assign to each ASV with pid >= cutoff the original barcode and then pool the sequences
  # (the counts of each ASV with pid >= cutoff will be summed to the ones of the NMBC)
  pidseq_filter = seqtab_df %>% 
    mutate(seq_names = ifelse(pid >= pid_cutoff_nmbc, nmbc, seq_names)) %>%
    dplyr::select(seq_names, all_of(sample_columns), pid) %>%
    group_by(seq_names) %>%
    dplyr::summarise_at(sample_columns, sum) %>%
    merge(dplyr:: select(seqtab_df, seq_names, seq), by = "seq_names")
  pidseq_filter_dim = nrow(pidseq_filter)
  
  # Now sort ASV by total frequency and assign an ASV ID
  seqtab_df_clean_asv <-
    tibble(pidseq_filter) %>%
    mutate(asv_total_freq = rowSums(across(where(is.numeric)))) %>%
    arrange(-asv_total_freq)  %>%
    mutate(asv_names = seq_names)
  # Find Row for NMBC
  seqtab_df_clean_nmbc <- seqtab_df_clean_asv[stringr::str_detect(string = seqtab_df_clean_asv$seq_names, pattern = "NMBC"),]
  
  # skip NMBC
  seqtab_df_clean_asv <-
    seqtab_df_clean_asv %>%
    filter(!stringr::str_detect(string = seq_names, pattern = "NMBC")) 
  # create ASV count
  seqtab_df_clean_asv$asv_names <- paste0("ASV", 
                                          formatC(c(1:nrow(seqtab_df_clean_asv)), 
                                                  width = nchar(trunc(nrow(seqtab_df_clean_asv))), 
                                                  format = "d", flag = "0")) # -1 to start 00 with no changes sequence
  # add back row with "seqtab_df_perf_match"  
  seqtab_df_clean_asv <-
    seqtab_df_clean_asv %>%
    add_row(seqtab_df_clean_nmbc) %>%
    arrange(-asv_total_freq) %>%
    dplyr::select(-c("seq_names", "asv_total_freq")) %>%
    relocate(asv_names)
  # final number of ASVs for analysis
  clean_asv <- nrow(seqtab_df_clean_asv)
  # save csv with final ASvs
  utils::write.csv(seqtab_df_clean_asv, file.path(output_dir, "/clean_asv_dataframe.csv"), row.names = F)
  
  REvoBC_object$clean_asv_dataframe = seqtab_df_clean_asv
  REvoBC_object = asv_statistics(REvoBC_object, 
                                 sample_columns, 
                                 asv_count_cutoff,
                                 figure_dir,
                                 nmbc,
                                 output_dir = output_dir)

  
  if(output_figures) {
    # assemble data  with all number for each step of filtering
    track_data <- data.frame(name=as.factor(c("Starting ASVs", "Chimeric Seq. Filter", "Flanking Seq. Filter", "Similarity Seq. Filter", "Final ASVs")), num=c(orgseq, chimseq_filter, endseq_filter, pidseq_filter_dim, clean_asv))
    # set order of columns DGN
    track_data <- dplyr::mutate(track_data, name = fct_relevel(name, c("Starting ASVs", "Chimeric Seq. Filter", "Flanking Seq. Filter", "Similarity Seq. Filter", "Final ASVs")))
    track_data$num_names <- paste0(track_data$num, " x ASVs") # numbers of ASV included on the top of bar  
    
    # calculate percent change from previous filter
    track_data <-
      track_data %>%
      mutate(track_data, diff_perc = ceiling(x=(num/lag(num)-1)*100)) %>%
      mutate(diff_perc = paste0(diff_perc, " %")) %>%
      mutate(diff_perc = if_else(name == "Starting ASVs" | name == "Final ASVs", "", diff_perc)) %>%
      mutate(num_names_sf = if_else(name == "Starting ASVs" | name == "Final ASVs", num_names, "")) %>%
      mutate(num_names_ins = if_else(name == "Starting ASVs" | name == "Final ASVs", "", num_names))

    # start graph 
    seqtab_df_clean_track <-
      ggplot(data=track_data) +
      geom_bar(aes(x=name, y=num, fill=name), position = "dodge", stat = "identity", width=0.8, size=0.2, show.legend = FALSE) +
      geom_text(aes(x=name, y=num, label=num_names_sf), vjust=-0.25, size=3) + # change order to have up whatever you choose, opposte to order
      geom_text(aes(x=name, y=num, label=num_names_ins), vjust=-1.75, size=3) + # change order to have up whatever you choose, opposte to order
      geom_text(aes(x=name, y=num, label=diff_perc), vjust=-0.25, size=3, col="blue") + # change order to have up whatever you choose, opposte to order
      scale_y_continuous(expand = c(0, 0), 
                         limits= c(0, plyr::round_any(max(track_data$num), 100, f = ceiling)+100/4), 
                         breaks = seq(0, (plyr::round_any(max(track_data$num), 100, f = ceiling)), 100)) +
      scale_fill_manual(values=c("#444c5c", "#aaaaaa", "#aaaaaa", "#aaaaaa", "#78a5a3")) +
      labs(x = "ASVs Filtering Steps", y = "Number of ASVs") + 
      lemon::coord_capped_cart(left="both") + # axis with lemon
      barplot_nowaklab_theme() + # add theme 
      theme(plot.margin = unit(c(0, 0, 0, 0), "mm"), # update theme specifically 
            axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), # , hjust = 1, vjust = 1
            axis.line.x = element_blank(), # disable x axis lines
            axis.ticks.x = element_blank()) # disable x axis ticks lines
    ggsave(filename="~/Desktop/track_asv_number.pdf", plot=seqtab_df_clean_track, width=15, height=12.5, units = "cm")
    # save pdf
    #ggsave(filename=file.path(figure_dir, "track_asv_number.pdf"), plot=seqtab_df_clean_track, width=15, height=15, units = "cm")
    # save csv
    write.csv(track_data, file.path(figure_dir, "/track_asv_number_data.csv"), row.names = FALSE, quote = FALSE)
  }
  
  return(REvoBC_object)
  
}

#' This function performs multi-sequence alignment and outputs statistics about mutations. 
#' Multiple Sequence Alignment is performed through the \href{https://bioconductor.org/packages/release/bioc/html/muscle.html}{MUSCLE} algorithm.
#' This function also compute the binary matrix indicating the presence/absence of
#' mutations in each ASV. Each mutation is characterized by a start position and an end position, it is thus identified through an ID
#' which indicates the start, end and type of mutation.
#' 
#' @title perform_msa
#' 
#' @examples 
#' data(revo_analyzed)
#' output_dir = system.file("extdata", "output", package = "REvoBC")
#' revo_analyzed$output_directory = output_dir
#' revo_msa = perform_msa(revo_analyzed)
#' 
#' @param REvoBC_object REvoBC object on which we want to perform msa.
#' @param ... Optional parameters (options and flags) passed to MUSCLE. See the \href{http://www.drive5.com/muscle/muscle_userguide3.8.html}{original guide} for detailed information on all possible options.
#' 
#' @return REvoBC object with a new field named \code{alignment}, which is a list with the following fileds:
#' \itemize{
#' \item \code{msa_stringset}: output of MSA peformed with MUSCLE.
#' \item \code{mutations_df} : (deprecated, will be removed).
#' \item \code{asv_barcode_alignment}: tibble where each line corresponds to a position in a ASV, and the columns encode the following information:
#' \itemize{
#' \item asv_names: name of the ASV
#' \item sample: sample identifier
#' \item position_bc260: position of the alteration in the original barcode. Note that insertions
#' are assigned to the position that coincides with their beginning.
#' \item alt: type of alteration. wt = Wild Type (i.e. non-mutated position). sub = substitution. del = deletion. ins = insertion.
#' \item{ref_asv}, \item{read_asv}: respectively, the reference nucleotide observed in the original barcode and the one observed on the sequence.
#' }
#' \item \code{ASV_alterations_width}: number of alterations for each type in each ASV
#' \item \code{mutations_coordinates}: tibble that stores all mutations identified on each ASV, indicating the start and end position and the nucleotides involved in the mutation
#' \item \code{binary_mutation_matrix}: binary matrix encoding presence/absence of mutations on ASVs.
#' \item \code{mutations_frequency}: tibble where for each position in each ASV you have the information about the frequency of the observed ASV in the sample.
#' This is useful to convey an idea about what is the fraction of total ASVs in each sample that are affected by that mutation in that position.
#' }. 
#' It also creates a new field in the REvoBC object called \code{smoothed deletions}, which contains the following information for
#' all the deletions identified in the ASVs, whose start and end site have been smoothed using the known cutting sites.
#' Smoothing is performed in the following way: the start site of each deletion is assigned to the cutting site on their left if that
#' is less distant then 5 nucleotides, otherwise they are assigned to the cutting site on their right. The end site is assigned to the 
#' cutting site on its right if that is less than 5 nucleotides distant, otherwise it is assigned to the cutting site
#' on its left.
#' The following dataframes are stored in the field \code{smoothed deletions}:
#' \itemize{
#' \item binary_matrix: matrix |ASV| x |mutations|, which contains 1/0 if the mutation is respectively present or not in the ASV.
#' \item coordinate_matrix: matrix which stores all the information regardin the smoothed deletions. Information include start and end before smoothing and the deleted sequence.
#' }
#' In addition, the following files are saved in the sub-folder "msa" created in the output directory chosen by the user:
#' \itemize{
#' \item dnastringset.fa: fasta file where the sequences are stored.
#' \item dnastringset.fa: same as fasta, but in csv format.
#' \item dnastringset_muscle-muscle_msa.fasta: fasta with the stringset resulted from MUSCLE.
#' \item ASV_alterations_width.csv: number of alterations for each type in each ASV
#' \item mutations_frequency.csv: per sample normalized frequency of each alteration type, computed for each position of the barcode in each sample.
#' \item mutations_df.csv: content of mutations_df variable explained above.
#' \item mutations_coordinates: content of mutations_coordinates variable explained above.
#' \item binary_mutation_matrix: content of binary_mutation_matrix variable explained above.
#' }
#' All identified mutations are displayed in a heatmap, saved inside the folder \code{msa_figures}.
#' This function also produces an output figure that contain the frequency of 
#' deletion, substitutions and insertions found in the different samples.
#' 
#' @export perform_msa
#' @rawNamespace import(dplyr, except = count)
#' @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
#' @import tibble
#' @rawNamespace import(data.table, except = c(last, first, between))
#' @importFrom muscle muscle
#' @importFrom Biostrings DNAStringSet writeXStringSet DNAMultipleAlignment
#' @importFrom ggmsa tidy_msa 
#' @importFrom lemon coord_capped_cart facet_rep_grid
#' @importFrom utils write.csv
#' @importFrom forcats fct_relevel
# @importFrom grDevices cairo_pdf
#' @importFrom stringr str_replace str_detect
#' @importFrom methods as
#' @importFrom tidyr pivot_wider
#' @importFrom pheatmap pheatmap 
#' @importFrom plyr count
perform_msa = function(REvoBC_object, ...) {
  dots = list(...)
  output_dir_files = file.path(REvoBC_object$output_directory, "msa")
  if(!dir.exists(output_dir_files)) dir.create(output_dir_files)
  
  output_dir_figures = file.path(REvoBC_object$output_directory, "msa_figures")
  if (!dir.exists(output_dir_figures)) {dir.create(output_dir_figures)}
  
  # Store in the field REvoBC_object$alignment$asv_barcode_alignment the tidy alignment
  # data, which is a tibble where each line corresponds to a nucleotide in a ASV
  # and there is the information about reference and alternative nucleotides.
  REvoBC_object = align_asv(REvoBC_object, output_dir_files, output_dir_figures)
  
  REvoBC_object = count_alterations(REvoBC_object, 
                                    output_dir_files,
                                    output_dir_figures)
  
  REvoBC_object = binary_mutation_matrix(REvoBC_object, 
                                         output_dir_files, 
                                         output_dir_figures)
  
  return(REvoBC_object)
  
}

#' This function calls Rmix from package Rphylip to perform the inference of the phylogeny
#' with Camin-Sokal.
#' 
#' @title infer_phylogeny
#' 
#' @examples 
#' \dontrun{
#' data(revo_msa)
#' output_dir = system.file("extdata", "output", package = "REvoBC")
#' revo_msa$output_directory = output_dir
#' revo_phyl = infer_phylogeny(revo_msa, phylip_package_path = 'D:/Programmi/phylip-3.698/exe/')
#' }
#' 
#' @param REvoBC_object (Required)
#' @param phylip_package_path (Required). Prior to running this function, users should install 
#' \href{https://evolution.genetics.washington.edu/phylip.html}{PHYLIP} and then provide the path to the folder containing the executable of mix.
#' For example, if in Windows a user stores the folder of phylip in path \code{D:/Programs/phylip},
#' then the value of \code{phylip_package_path} should be set to \code{D:/Programs/phylip/exe/}.
#' @param mutations_use (optional). Default = 'smooth_del' A string indicating what type of utations to use for phylogeny reconstruction.
#' Can be one of c('smooth_del', 'smooth_del_ins', sub_smooth_del_ins, sub_del_ins). The first
#' corresponds to using only smoothed deletions. The second refers to the case where smoothed deletions
#' and insertios are considered. The third considers the smoothed deletions/insertions and the substitutions. 
#' Finally the fourth uses all non-smoothed mutations.
#' 
#' @return REvoBC object with a new filed called phylogeny, that stores the inferred tree.
#' 
#' @export infer_phylogeny
#' @importFrom Rphylip Rmix
#' @importFrom scales comma
#' @importFrom phytools mrp.supertree
#' @importFrom TreeTools RootTree
#' @importFrom ggtree fortify
#' @importFrom dynamicTreeCut cutreeDynamic
#' @importFrom ape cophenetic.phylo bind.tree drop.tip
#' @importFrom phylogram as.dendrogram
#' @rawNamespace import(dplyr, except = count)
#' @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
#' @import lemon
infer_phylogeny = function(REvoBC_object, phylip_package_path, mutations_use = 'smooth_del') {
  
  if (! (mutations_use %in% c('smooth_del', 'smooth_del_ins', 'sub_smooth_del_ins', 'sub_del_ins'))) {
    cli::cli_alert_danger("Error, muations use must be one of 'smooth_del', 'smooth_del_ins', 'sub_smooth_del_ins', 'sub_del_ins'")
    stop('Exiting')
  }
  REvoBC_object$phylogeny$mutations_in_phylogeny = mutations_use
  output_dir = file.path(REvoBC_object$output_directory, paste0("phylogeny_", mutations_use))
  
  if (!dir.exists(output_dir)) {dir.create(output_dir)}
  
  if (mutations_use == 'smooth_del') {
    asv_bin_var = REvoBC_object$smoothed_deletions_insertions$binary_matrix %>% 
      dplyr::select(starts_with('del_')) 
    barcode_var = asv_bin_var[REvoBC_object$barcode$asv_names,]
    asv_bin_var = barcode_var %>% 
      dplyr::bind_rows(asv_bin_var %>% 
                         filter(rowSums(dplyr::across(dplyr::everything())) > 0))
  } else if (mutations_use == 'smooth_del_ins'){
    asv_bin_var = REvoBC_object$smoothed_deletions_insertions$binary_matrix %>%
      dplyr::select(starts_with('ins_') | starts_with('del_')) 
    barcode_var = asv_bin_var[REvoBC_object$barcode$asv_names,]
    asv_bin_var = barcode_var %>% 
      dplyr::bind_rows(asv_bin_var %>% 
                         filter(rowSums(dplyr::across(dplyr::everything())) > 0))
  } else if (mutations_use == 'sub_smooth_del_ins') {
    asv_bin_var = REvoBC_object$smoothed_deletions_insertions$binary_matrix
  } else {
    asv_bin_var = REvoBC_object$alignment$binary_mutation_matrix 
  }

  tree_mp = compute_phylogenetic_tree(asv_bin_var, phylip_package_path, REvoBC_object$barcode$asv_names)
  
  # Re-fortify tree to data frame
  options(warn=-1)
  tree_mp_df <- ggtree::fortify(tree_mp)
  options(warn=0)
  
  dend_clustered = cut_phyl_dendogram(tree_mp)
  
  cluster_labels = sort(unique(dend_clustered$cluster))[-1]
  # clusters_trees = list()
  # clusters_trees_df = list()
  binded_phylogenies = NULL
  i = 0
  if (length(cluster_labels) > 0) {
    for (clust in cluster_labels) {
      subset_asv = dend_clustered %>% filter(cluster == clust) %>% pull(asv_names)
      subset_mut = asv_bin_var %>% tibble::rownames_to_column(var = 'asv_names') %>%
        filter(asv_names %in% subset_asv | asv_names == REvoBC_object$barcode$asv_names) %>%
        tibble::column_to_rownames('asv_names') #%>% dplyr::select_if(sum(.) > 0)
      subset_mut = subset_mut[,colSums(subset_mut)>0]
      tree_sub = compute_phylogenetic_tree(subset_mut, phylip_package_path, REvoBC_object$barcode$asv_names)
      
      if (i > 0) {
        binded_phylogenies = ape::bind.tree(x = binded_phylogenies, y = tree_sub)
      } else {
        binded_phylogenies = tree_sub
      }
      i = i + 1
      # clusters_trees[[clust]] <- tree_sub
      # clusters_trees_df[[clust]] <- ggtree::fortify(tree_sub)
      
    }
  }

  # The binded phylogeny now has as many barcode nodes as the number of clusters.
  # We need to remove all barcodes except for one (so, count the number of barcodes),
  # leave only the one with y = 1 and subtract to all the other nodes the number of removed barcode nodes.
  tips_barcode = ggtree::fortify(binded_phylogenies) %>% 
    filter(label == REvoBC_object$barcode$asv_names & y != 1) %>% pull(node)
  
  binded_phylogenies = ape::drop.tip(phy = binded_phylogenies, tip = tips_barcode)
  
    # filter(label != REvoBC_object$barcode$asv_names | y == 1) %>%
    # mutate(nuovo_y = ifelse(y != 1, y - length(cluster_labels) + 1, y))
  
  REvoBC_object$phylogeny$tree = ggtree::fortify(binded_phylogenies)
  REvoBC_object$phylogeny$phylogeny_clustered = dend_clustered
  
  write.csv(REvoBC_object$phylogeny$tree, file.path(output_dir, "phylogeny.csv"))
  
  return(REvoBC_object)
  
}

#' This function plots all the data that have been computed for the phylogenetic analysis.
#' 
#' @title plot_summary
#' 
#' 
#' @examples
#' \dontrun{
#' data(revo_phyl)
#' output_dir = system.file("extdata", "output", package = "REvoBC")
#' revo_phyl$output_directory = output_dir
#' summary_plot = plot_summary(revo_phyl)
#' }
#' 
#' @param REvoBC_object (Required).
#' @param sample_order (Optional). When visualizing the output, users can set the order in which they want the different samples to be visualized.
#' This is by default \code{alphabetical}: in this case all samples are sorted alphabetically. Users can also set this parameter to a list, such as c('PRL', 'HMR', 'LGR'), which would be used as the order of the samples. 
#' 
#' @return A summary plot is produced and stored in the output directory associated to the REvoBC object. This plot is composed by 7 panels: the first contains the tree representation; then, there is a graphical
#' representation of each ASV, that gives information about the position of all its mutations; next there is a barplot indicating the total number of nucletoides affected by each alteration type in each ASV;
#' next there is a second barplot indicating the length of each ASV; next we find a bubble plot, which encodes the percentage sequence similarity of each ASV with respect to the original barcode; finally, there is a dot plot
#' where the size of each dot indicate the frequency of each ASV normalized by the total counts found in the corresponding sample, and the color of the dot represent the count normalized to the highest counts found for the same ASV in another sample.
#' 
#' @export plot_summary
#' @rawNamespace import(ggplot2, except = c(element_render, CoordCartesian))
#' @import lemon
#' @import tibble
#' @import ggtree
#' @rawNamespace import(dplyr, except = count)
#' @importFrom scales comma
#' @importFrom colorspace scale_fill_continuous_sequential
#' @importFrom aplot insert_right insert_left
plot_summary = function(REvoBC_object, sample_order = 'alphabetical') {
  mut_in_phyl = REvoBC_object$phylogeny$mutations_in_phylogeny
  is_smoothed = grepl(pattern = 'smooth', x = mut_in_phyl)
  
  
  df_to_plot_perf_match = REvoBC_object$statistics$all_asv_statistics
  
  tree_mp_df = REvoBC_object$phylogeny$tree
  if (is_smoothed) {
    wt_asv = setdiff(REvoBC_object$alignment$mutations_df$asv_names, tree_mp_df$label)
    if (length(wt_asv) > 0) {
      # Need to re-insert the ASV without any smoothed mutation for the visualization
      barcode_tip = tree_mp_df %>% filter(label == REvoBC_object$barcode$asv_names)
      
      vary = 'y'
      tree_mp_df = tree_mp_df %>% filter(label != REvoBC_object$barcode$asv_names | is.na(label)) %>%
        #dplyr::mutate('{{var}}' = {{var}} + length(wt_asv)) %>%
        dplyr::mutate(y = y + length(wt_asv)) %>%
        add_row(parent = barcode_tip$parent, 
                node = c((max(tree_mp_df$node) + 1) : (max(tree_mp_df$node) + length(wt_asv))), 
                label = wt_asv,
                isTip = TRUE, x = barcode_tip$x, y = c(2:(1+length(wt_asv))),
                branch = barcode_tip$branch, angle = barcode_tip$angle) %>%
        add_row(barcode_tip)
      }
    }
  
  
  # merge with df_to_plot_perf_match
  
  if (is.character(sample_order) & length(sample_order) == 1) {
    if (sample_order != 'alphabetical') {
      stop('The ordering provided is not valid. Either use the default alphabetical or give a list of sample names.')
    }
    df_to_plot_perf_match = dplyr::arrange(df_to_plot_perf_match, sample, asv_names)
  } else {
    if (length(intersect(sample_order, df_to_plot_perf_match$sample)) != length(sample_order)) {
      cli::cli_alert_danger('The samples found in variable sample_order do not match the samples contained in the dataset.')
      cat("The following samples need to be provided: ", unique(df_to_plot_perf_match$sample))
      stop("Exiting")
    }
    df_to_plot_perf_match$sample = factor(df_to_plot_perf_match$sample, levels = sample_order)
    #= dplyr::arrange(df_to_plot_perf_match, match(sample, sample_order), asv_names)
  }
    
  df_to_plot_final <- tibble(merge(df_to_plot_perf_match, 
                                   REvoBC_object$alignment$ASV_alterations_width, 
                                   by.x="asv_names", by.y="asv_names"))
  
  
  width_nmbc <- dplyr::select(filter(df_to_plot_final, !str_detect(asv_names, "ASV")), 
                              all_of(starts_with('width_')))
  final_nmbc <- filter(df_to_plot_perf_match, str_detect(asv_names, "NMBC"))
  nmbc_mrg <- cbind(final_nmbc, width_nmbc)
  
  # add back NMBC
  df_to_plot_final <- rbind(df_to_plot_final, nmbc_mrg)
  df_to_plot_final$asv_names <- as.factor(df_to_plot_final$asv_names)
  
  tip_colors <-
    df_to_plot_perf_match %>%
    dplyr::filter(perc_fold_to_max == 100, !str_detect(asv_names, "NMBC")) %>% # find max in organ/day
    dplyr::select(asv_names, sample) %>%
    add_row(data.frame(asv_names=REvoBC_object$barcode$asv_names, sample="PRL"))
  colnames(tip_colors) <- c("asv_names", "sample_max_perc")
  
  tip_colors = merge(tip_colors, REvoBC_object$phylogeny$phylogeny_clustered, by = 'asv_names') %>%
    mutate(cluster = factor(cluster))
  
  sample_columns = sort(setdiff(colnames(REvoBC_object$clean_asv_dataframe), c("asv_names", "seq")))
  
  ggtree_mp = plot_phylogenetic_tree(tree_mp_df, sample_columns, tip_colors)
  
  if (is_smoothed)
    msa_cna_bc_smoothed = plot_msa(REvoBC_object, smoothed_deletions = mut_in_phyl)
  msa_cna_bc = plot_msa(REvoBC_object, smoothed_deletions = F)
  
  bar_ins_del_sub_width = plot_mutations_width(df_to_plot_final)
  
  bar_seq_n = plot_asv_length(df_to_plot_final)
  
  bar_pid = plot_similarity(df_to_plot_final)
  
  bubble = plot_percentage_asv_sample(df_to_plot_final)

  # Maximum Parsimony Based Tree with msa/Bubble (barcode scale) ------------------------------------------------------ 
  # msa and bar_seq_n
  if (is_smoothed) {
    msa_cna_bc = aplot::insert_right(msa_cna_bc_smoothed, msa_cna_bc, width = 1)
  }

  msa_cna_bc.bar_ins_del_sub_width <- aplot::insert_right(msa_cna_bc, bar_ins_del_sub_width, width = 0.25) 
  # add ggtree_mp
  msa_cna_bc.bar_ins_del_sub_width.ggtree_mp <- aplot::insert_left(msa_cna_bc.bar_ins_del_sub_width, ggtree_mp, width = 0.75)
  # add bar_seq_n
  msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n <- aplot::insert_right(msa_cna_bc.bar_ins_del_sub_width.ggtree_mp, bar_seq_n, width = 0.2)
  # add bar_pid
  msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n.bar_pid <- aplot::insert_right(msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n, bar_pid, width = 0.2)
  # add bubbles
  msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n.bar_pid.bubble <- aplot::insert_right(msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n.bar_pid, bubble, width = 0.2)
  
  # Save PDF
  ggsave(filename=file.path(REvoBC_object$output_directory, "summary_mutations.pdf"), 
         plot=msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n.bar_pid.bubble, width=80,
         height=dim(tree_mp_df)[1]*0.6, units = "cm", limitsize = FALSE)
  
  return(msa_cna_bc.bar_ins_del_sub_width.ggtree_mp.bar_seq_n.bar_pid.bubble)
}
